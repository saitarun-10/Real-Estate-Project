{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1256915d-d0b5-4251-b3d3-0d374cf1f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#User Agent\n",
    "headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b46ea-2af7-44ad-ad09-c1cefa8e2db5",
   "metadata": {},
   "source": [
    "## Overview \n",
    "This code sets up the necessary tools and headers to scrape web data. It imports libraries for sending HTTP requests, parsing HTML, and handling data. Additionally, it defines a user agent header to mimic a web browser, which can be useful to avoid getting blocked by some websites.\n",
    "- **import requests**\n",
    "This line imports the requests module, which is a popular Python module used to send HTTP requests to websites.\n",
    "- **from bs4 import BeautifulSoup** \n",
    "This line imports BeautifulSoup from the bs4 module. BeautifulSoup is a library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree that can be used to extract data in a hierarchical and more readable manner.\n",
    "- **import os**\n",
    "This line imports the os module, which provides a way of interacting with the operating sysyem. This could be used for tasks like creating directories, reading environment variables etc.\n",
    "- **headers = {...}**\n",
    "This line defines a dictionary called headers with a 'User-Agent' key. The value of this key is a string that represents a user agent string.\n",
    "The user agent string is used to tell the server about the browser and operating system of the user. Some websites serve different content based on the user agent or even block certain user agents (often to prevent scraping). By defining a common browser's user agent string, this code is trying to mimic a real browser request to potentially avoid blocks or get the same content a real user would see.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28384cdb-8e7c-41b1-bd95-e495217e7a74",
   "metadata": {},
   "source": [
    "### Extracting Flats/Apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462c4b58-3fc5-4dcc-850a-52ffc1547262",
   "metadata": {},
   "outputs": [],
   "source": [
    "flats = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f86cfd-db30-4677-a3f1-0bf93943d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 127\n",
    "end = 200\n",
    "csv_file = f\"Real Estate Project/flats_gurgaon_data-p{start}-{end}.csv\"\n",
    "\n",
    "pageNumber = start\n",
    "req=0\n",
    "\n",
    "city = 'gurgaon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d593d3-1ac5-4181-a490-4aeb27b45de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while pageNumber < end:\n",
    "    i=1\n",
    "    url = f\"https://www.99acres.com/flats-in-{city}-ffid-page-{pageNumber}\"\n",
    "    page = requests.get(url, headers=headers)\n",
    "    pageSoup = BeautifulSoup(page.content,'html.parser')\n",
    "    req += 1\n",
    "    for soup in pageSoup.select_one('div[data-label=\"SEARCH\"]').select('section[data-hydration-on-demands=\"true\"]'):\n",
    "    # Extract propert name and property sub_name\n",
    "        try:\n",
    "            property_name = soup.select_one('a.srpTuple__propertyName').text.strip()\n",
    "            # Extract Link\n",
    "            link = soup.select_one('a.srpTuple__propertyName')['href']\n",
    "            society = soup.select_one('#srp_tuple_society_heading').text.strip()\n",
    "        except:\n",
    "            continue\n",
    "        # Detail Page\n",
    "        page = requests.get(link,headers=headers)\n",
    "        dpageSoup = BeautifulSoup(page.content,'html.parser')\n",
    "        req += 1\n",
    "        try:\n",
    "            # price range\n",
    "            price = dpageSoup.select_one('#pdPrice2').text.strip()\n",
    "        except:\n",
    "            price = ''\n",
    "\n",
    "        # Area\n",
    "        try:\n",
    "            area = dpageSoup.select_one('#srp_tuple_price_per_unit_area').text.strip()\n",
    "        except:\n",
    "            area = ''\n",
    "        # Area with Type\n",
    "        try:\n",
    "            areaWithType = dpageSoup.select_one('#factArea').text.strip()\n",
    "        except:\n",
    "            areaWithType = ''\n",
    "\n",
    "        # Configuration\n",
    "        try: \n",
    "            bedRoom = dpageSoup.select_one('#bedRoomNum').text.strip()\n",
    "        except:\n",
    "            bedRoom = ''\n",
    "        try:\n",
    "            bathroom = dpageSoup.select_one('#bathroomNum').text.strip()\n",
    "        except:\n",
    "            bathroom=''\n",
    "        try:\n",
    "            balcony = dpageSoup.select_one('#balconyNum').text.strip()\n",
    "        except:\n",
    "            balcony = ''\n",
    "        try:\n",
    "            additionalRoom = dpageSoup.select_one('#additionalRooms').text.strip()\n",
    "        except:\n",
    "            additionalRoom = ''\n",
    "\n",
    "        # Address\n",
    "        try:\n",
    "            address = dpageSoup.select_one('#address').text.strip()\n",
    "        except:\n",
    "            address = ''\n",
    "        # Floor Number\n",
    "        try:\n",
    "            floorNum = dpageSoup.select_one('#floorNumLabel').text.strip()\n",
    "        except:\n",
    "            floorNum = ''\n",
    "        try:\n",
    "            facing = dpageSoup.select_one('#facingLabel').text.strip()\n",
    "        except:\n",
    "            facing = ''\n",
    "        try:\n",
    "            agePossession = dpageSoup.select_one('#agePossessionaLbl').text.strip()\n",
    "        except:\n",
    "            agePossession = ''\n",
    "        # Nearby Locations\n",
    "        try:\n",
    "            nearbyLocations = [i.text.strip() for i in dpageSoup.select_one('div.NearByLocation__tagWrap').select('span.NearByLocation__infoText')]\n",
    "        except:\n",
    "            nearbyLocations = ''\n",
    "        # Descriptions\n",
    "        try:\n",
    "            description = dpageSoup.select_one('#description').text.strip()\n",
    "        except:\n",
    "            description = ''\n",
    "        # Furnish Details\n",
    "        try:\n",
    "            furnishDetails = [i.text.strip() for i in dpageSoup.select_one('#FurnishDetails').select('li')]\n",
    "        except:\n",
    "            furnishDetails = ''\n",
    "        # Features\n",
    "        if furnishDetails:\n",
    "            try:\n",
    "                features = [i.text.strip() for i in dpageSoup.select('#features')[1].select('li')]\n",
    "            except:\n",
    "                features = ''\n",
    "        else:\n",
    "            try:\n",
    "                features = [i.text.strip() for i in dpageSoup.select('#features')[0].select('li')]\n",
    "            except:\n",
    "                features = ''\n",
    "\n",
    "        # Rating by Features\n",
    "        try:\n",
    "            rating = [i.text.strip() for i in dpageSoup.select_one('div.review__rightSide>div>ul>li>div').select('div.ratingByFeature__circleWrap')]\n",
    "        except:\n",
    "            rating = ''\n",
    "        # print(top_f)\n",
    "        try:\n",
    "            # Property ID\n",
    "            property_id = dpageSoup.select_one('#Prop_Id').text.strip()\n",
    "        except:\n",
    "            property_id = ''\n",
    "\n",
    "        # Create a dictionary with the given variables\n",
    "        property_data = {\n",
    "            'property_name':property_name,\n",
    "            'link' : link,\n",
    "            'society' : society,\n",
    "            'price':price,\n",
    "            'area':area,\n",
    "            'areaWithType': areaWithType,\n",
    "            'bedRoom':bedRoom,\n",
    "            'bathroom':bathroom,\n",
    "            'balcony':balcony,\n",
    "            'additionalRoom':additionalRoom,\n",
    "            'address':address,\n",
    "            'floorNum':floorNum,\n",
    "            'facing':facing,\n",
    "            'agePossession':agePossession,\n",
    "            'nearbyLocations':nearbyLocations,\n",
    "            'description':description,\n",
    "            'furnishDetails':furnishDetails,\n",
    "            'features':features,\n",
    "            'rating':rating,\n",
    "            'property_id':property_id\n",
    "        }\n",
    "\n",
    "        temp_df = pd.DataFrame.from_records([property_data])\n",
    "        # print(temp_df)\n",
    "        flats = pd.concat([flats,temp_df], ignore_index=True)\n",
    "        i += 1\n",
    "        if os.path.isfile(csv_file):\n",
    "            temp_df.to_csv(csv_file,mode='a',header=False,index=False)\n",
    "        else:\n",
    "            temp_df.to_csv(csv_file,mode='a',header=False,index=False)\n",
    "\n",
    "        if req %4==0:\n",
    "            time.sleep(10)\n",
    "        if req %15==0:\n",
    "            time.sleep(50)\n",
    "    print(f'{pageNumber} -> {i}')\n",
    "    pageNumber += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55853ff2-952d-45aa-b8e3-f7f597a9c1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799d400-29ad-48da-871f-ca80eb41678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c3a41-73b9-43fe-aa18-a049c1aadf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00719ac8-1a65-4e64-8517-ee1b415725fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b78e4d-317e-492d-b037-fd032ae950c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2c4cd-bccb-400e-a990-b3dfafa94c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d933349-ae77-4dc7-a6d8-f15aa1c2e20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
